{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - utiliser juste deux classes : keep / reject\n",
    " - multi-variate X en fonction du dictionaire incluant list_keys_param_fit et goodness_of_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn import svm, datasets\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 1- Split into a training set and a test set using a ShuffleSplit + doing that in parallel for the differrent features to test\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "def split_data(X, y, test_size=.25, train_size=None) :\n",
    "    \n",
    "\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=test_size, train_size=train_size, random_state=0)\n",
    "    for index_train, index_test in rs.split(y): pass\n",
    "\n",
    "    X_train, X_test = {}, {}\n",
    "    X_train, X_test = X[index_train, :], X[index_test, :]\n",
    "    y_train, y_test =  y[index_train].copy(), y[index_test].copy()\n",
    "\n",
    "    print('nb_trial_train : X: %s, y: %s'%(X_train.shape[0], y_train.shape[0]), end='\\t')\n",
    "    print('nb_trial_test : X: %s,  y: %s'%(X_test.shape[0], y_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 4- Train a SVM classification model\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def Train_SVM(X_train, y_train, size_c_gamma=32, ax=None, fig=None, plot=None) :\n",
    "\n",
    "\n",
    "    C_range = np.logspace(-5, 10., size_c_gamma, base=2.)\n",
    "    gamma_range = np.logspace(-14, 3, size_c_gamma, base=2.)\n",
    "\n",
    "    #param_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': gamma_range, 'C': C_range}, {'kernel': ['linear'], 'C': C_range}]\n",
    "    \n",
    "    liste_kernel = ['rbf']#, 'poly', 'sigmoid']\n",
    "    param_grid = [{'kernel': liste_kernel, 'gamma': gamma_range, 'C': C_range}]\n",
    "\n",
    "    \n",
    "    grid = GridSearchCV(SVC(verbose=False, tol=1e-3, max_iter = -1, class_weight='balanced'),\n",
    "                        param_grid, verbose=0, scoring='balanced_accuracy', n_jobs=1,) #cv=50, n_jobs=-1\n",
    "    \n",
    "\n",
    "    X_train_ = np.zeros((len(X_train), 0))\n",
    "    X_train_ = np.hstack((X_train_, X_train))\n",
    "    grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "    # plot the scores of the grid\n",
    "    #score_dict = grid.grid_scores_ # grid_scores_ contains parameter settings and scores\n",
    "    \n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    \n",
    "    scores_mean, scores_std = {}, {}\n",
    "    #for params, mean_score, scores in score_dict:\n",
    "    for mean_score, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        try :\n",
    "            scores_mean[params['kernel']].append(mean_score)\n",
    "            scores_std[params['kernel']].append(std)\n",
    "        except:\n",
    "            scores_mean[params['kernel']] = []\n",
    "            scores_std[params['kernel']] = []\n",
    "            scores_mean[params['kernel']].append(mean_score)\n",
    "            scores_std[params['kernel']].append(std)\n",
    "\n",
    "\n",
    "    # draw heatmap of accuracy as a function of gamma and C\n",
    "    if plot is None :\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "    for x, k in enumerate(['rbf']): #, 'poly', 'sigmoid']) :\n",
    "        scores = np.array(scores_mean[k]).reshape((gamma_range.shape[0], C_range.shape[0]))\n",
    "        im = ax.imshow(scores, interpolation='nearest', cmap=plt.cm.gray, vmin=0, vmax=1)\n",
    "        ax.set_xlabel('gamma')\n",
    "        ax.set_ylabel('C')\n",
    "        #ax.set_colorbar()\n",
    "\n",
    "        ax.set_xticks(range(0, len(gamma_range), 5))\n",
    "        ax.set_yticks(range(0, len(C_range), 5))\n",
    "        ax.set_xticklabels(['%0.4f'%gamma_range[num] for num in range(0, len(gamma_range), 5)])\n",
    "        ax.set_yticklabels(['%0.4f'%C_range[num] for num in range(0, len(C_range), 5)])\n",
    "        \n",
    "        \n",
    "        ax.set_title(k)\n",
    "        fig.colorbar(im, ax=ax, pad=0.01, fraction=.047)\n",
    "    \n",
    "    if plot is None :\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"The best parameters are %s with a score of %0.2f\" % (grid.best_params_, grid.best_score_))\n",
    "    \n",
    "    if plot is None : return grid\n",
    "    else : return ax, fig, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 5- Quantitative evaluation of the model quality on the test set\n",
    "#------------------------------------------------------------------------------\n",
    "def Quantitative_evaluation(grid, X_test, y_test, classes, ax=None, fig=None, plot=None) :\n",
    "\n",
    "    import itertools\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    \n",
    "    y_pred = grid.predict(X_test)\n",
    "    \n",
    "    fone_score = np.array(metrics.f1_score(y_test, y_pred, average=None)).mean()\n",
    "    #fone_score = np.array(metrics.balanced_accuracy_score(y_test, y_pred)).mean()\n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    if plot is None : fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    im = ax.imshow(norm_cm, interpolation='nearest', cmap=plt.cm.Reds, vmin=0, vmax=1)\n",
    "    \n",
    "    ax.set_title('Confusion matrix\\n(fone_score on test => Accuracy = %0.2f)' % (fone_score))\n",
    "    fig.colorbar(im, ax=ax, pad=0.01, fraction=.047)\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = norm_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, 'nb_trial = %s\\n\\n(%.0f %%)'%(cm[i, j], norm_cm[i, j]*100),\n",
    "                 ha=\"center\", color=\"white\" if norm_cm[i, j] > thresh else \"black\")\n",
    "        if i==j :\n",
    "            ax.text(j, i+0.2, 'f1_score = %.2f'%(metrics.f1_score(y_test, y_pred, average=None)[i]),\n",
    "                 ha=\"center\", color=\"white\" if norm_cm[i, j] > thresh else \"black\")\n",
    "    \n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    \n",
    "    if plot is None :\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return y_pred\n",
    "    else :\n",
    "        return ax, fig, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from ANEMO import read_edf\n",
    "from ANEMO import ANEMO\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sujet = ['AM','BMC','CS','DC','FM','IP','LB','OP','RS','SR','TN','YK']\n",
    "time = ['2017-10-23_100057','2017-09-26_095637', '2017-10-03_134421','2017-09-27_161040',\n",
    "        '2017-10-03_143803','2017-09-28_115250', '2017-09-20_151043','2017-10-26_121823',\n",
    "        '2017-11-08_094717','2017-11-16_153313', '2017-11-08_150410','2017-11-17_172706']\n",
    "file = os.path.join('parametre', 'Delete_list_trials_velocity_fct.pkl')\n",
    "with open(file, 'rb') as fichier :\n",
    "    Delete_list_trials = pickle.load(fichier, encoding='latin1')\n",
    "\n",
    "file = os.path.join('parametre', 'Delete_list_Bad_trials_velocity.pkl')\n",
    "with open(file, 'rb') as fichier :\n",
    "    Bad_Fit = pickle.load(fichier, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "list_keys_param_fit = ['start_anti', 'tau', 'v_anti', 'latence', 'maxi']\n",
    "X, y, var = [], [], []\n",
    "a = 0\n",
    "for x in range(len(sujet)) :\n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    file = os.path.join('data', 'enregistrement_' + sujet[x] + '_' + time[x] + '.pkl')\n",
    "    with open(file, 'rb') as fichier : param_exp = pickle.load(fichier, encoding='latin1')\n",
    "    A = ANEMO(param_exp)\n",
    "    N_trials, N_blocks = param_exp['N_trials'], param_exp['N_blocks']\n",
    "\n",
    "    resultats = os.path.join('data', 'enregistrement_' + sujet[x] + '_' + time[x] + '.asc')\n",
    "    data = read_edf(resultats, 'TRIALID')\n",
    "\n",
    "    file = os.path.join('parametre/goodness_of_fit_'+ sujet[x] +'.pkl')\n",
    "    with open(file, 'rb') as fichier : goodness_of_fit = pickle.load(fichier, encoding='latin1')\n",
    "    \n",
    "    file = os.path.join('parametre/param_Fit_'+ sujet[x] +'_fct_velocity_2_step_False_whitening.pkl')\n",
    "    with open(file, 'rb') as fichier : param_fit = pickle.load(fichier, encoding='latin1')\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    nb_del_trial = [len(Delete_list_trials[sujet[x]][b]) for b in range(N_blocks)]\n",
    "    nb_bad_trial = [len(Bad_Fit[sujet[x]][b]) for b in range(N_blocks)]\n",
    "    print('%s -- nb_Delete_trials = %s, nb_Bad_Fit = %s'%(sujet[x], nb_del_trial, nb_bad_trial))\n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    for block in range(N_blocks) :\n",
    "        for trial in range(N_trials) :\n",
    "\n",
    "            if trial in Delete_list_trials[sujet[x]][block] : y.append(1)\n",
    "            elif trial in Bad_Fit[sujet[x]][block] : y.append(1)\n",
    "            else : y.append(0)\n",
    "\n",
    "            if a==0 :\n",
    "                var.append('nb_nan') ; X.append([])\n",
    "                var.append('residu') ; X.append([])\n",
    "                for key in goodness_of_fit.keys() :\n",
    "                    if key!='residual' : var.append(key) ; X.append([])\n",
    "                for key in param_fit.keys() :\n",
    "                    if key in list_keys_param_fit : var.append(key) ; X.append([])\n",
    "                a=1\n",
    "            \n",
    "            trial_data = trial + N_trials*block\n",
    "            arg = A.arg(data[trial_data], trial=trial, block=block)\n",
    "            velocity_NAN = A.velocity_NAN(**arg)[0]\n",
    "\n",
    "            nb_nan = [x for x in velocity_NAN[arg.StimulusOf-arg.t_0:] if str(x)=='nan']\n",
    "            X[0].append(len(nb_nan)/len(velocity_NAN[arg.StimulusOf-arg.t_0:]))\n",
    "            \n",
    "            t1 , res = 0, np.zeros(len(velocity_NAN)-280)\n",
    "            for t in range(len(velocity_NAN)-280) :\n",
    "                if np.isnan(velocity_NAN[t]) : res[t] = np.nan\n",
    "                else : res[t] = abs(goodness_of_fit['residual'][block][trial][t1]) ; t1 = t1+1\n",
    "            residu = np.nanmean(res[arg.StimulusOf-arg.t_0:])\n",
    "            \n",
    "            X[1].append(residu)\n",
    "            \n",
    "            k = 2\n",
    "            for key in goodness_of_fit.keys() :\n",
    "                if key!='residual' : X[k].append(goodness_of_fit[key][block][trial]) ; k=k+1\n",
    "    \n",
    "            for key in param_fit.keys() :\n",
    "                if key in list_keys_param_fit : X[k].append(param_fit[key][block][trial]) ; k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(var)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(l_) :\n",
    "    \n",
    "    X0 = []\n",
    "    for a in l_ :\n",
    "        for b in range(len(var)) :\n",
    "            if a==var[b] :\n",
    "                X0.append(X[b])\n",
    "\n",
    "    X1 = np.array(X0) ; y1 = np.array(y)\n",
    "    X1 = X1.transpose()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X1, y1, test_size=.7, train_size=None)\n",
    "    print('nb_Bad_trial -- y_train : %s -- y_test : %s'%(len(y_train[y_train>0]), len(y_test[y_test>0])))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10*2,10))\n",
    "    X_fit = X_train ; X_t = X_test\n",
    "\n",
    "    classes = ['keep', 'reject']\n",
    "    ax[0], fig, grid = Train_SVM(X_fit, y_train, size_c_gamma=32, ax=ax[0], fig=fig, plot=True)\n",
    "    ax[1], fig, y_pred = Quantitative_evaluation(grid, X_t, y_test, classes, ax=ax[1], fig=fig, plot=True)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[nb_nan, residu, redchi,       bic, start_anti, maxi, latence, v_anti, tau]\n",
    "[nb_nan, residu,         nfev, bic, start_anti, maxi, latence, v_anti, tau]\n",
    "[nb_nan,         redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau]\n",
    "[        residu, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = ['nb_nan', 'residu', 'redchi',         'bic', 'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = ['nb_nan', 'residu',           'nfev', 'bic', 'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = ['nb_nan',           'redchi', 'nfev', 'bic', 'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "l_ = [          'residu', 'redchi', 'nfev', 'bic', 'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reporting..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "                                        List                                             --> score %keep %reject\n",
    "----------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .54    100%   0%\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti     ] --> .52    100%   0%\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence,         tau] --> .55    100%   0%\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi,          v_anti, tau] --> .55    100%   0%\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti,       latence, v_anti, tau] --> .52    100%   0%\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic,             maxi, latence, v_anti, tau] --> .56    100%   0%\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev,      start_anti, maxi, latence, v_anti, tau] --> .51     20%  94%\n",
    "[nb_nan, residu, aic, chisqr, redchi,       bic, start_anti, maxi, latence, v_anti, tau] --> .55    100%   1%\n",
    "[nb_nan, residu, aic, chisqr,         nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .53    100%   0%\n",
    "[nb_nan, residu, aic,         redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .57     94%  15%\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "        [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti     ] --> .58     56%  55%\n",
    "        [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi, latence,         tau] --> .58     53%  57%\n",
    "        [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi,          v_anti, tau] --> .68     64%  71%\n",
    "        [nb_nan, residu, aic, redchi, nfev, bic, start_anti,       latence, v_anti, tau] --> .67     66%  73%\n",
    "        [nb_nan, residu, aic, redchi, nfev, bic,             maxi, latence, v_anti, tau] --> .72     65%  73%\n",
    "        [nb_nan, residu, aic, redchi, nfev,      start_anti, maxi, latence, v_anti, tau] --> .72     56%  81% \n",
    "        [nb_nan, residu, aic, redchi,       bic, start_anti, maxi, latence, v_anti, tau] --> .71     73%  74%\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "              #[nb_nan, residu, aic, redchi, bic, start_anti, maxi, latence, v_anti     ] --> .70     65%  77%\n",
    "              #[nb_nan, residu, aic, redchi, bic, start_anti, maxi, latence,         tau] --> .68     74%  66%\n",
    "              #[nb_nan, residu, aic, redchi, bic, start_anti, maxi,          v_anti, tau] --> .69     75%  67%\n",
    "              #[nb_nan, residu, aic, redchi, bic, start_anti,       latence, v_anti, tau] --> .71     73%  74%\n",
    "              #[nb_nan, residu, aic, redchi, bic,             maxi, latence, v_anti, tau] --> .74     78%  70%\n",
    "              #[nb_nan, residu, aic, redchi,      start_anti, maxi, latence, v_anti, tau] --> .72     79%  68%\n",
    "              #-----------------------------------------------------------------------------------------------\n",
    "              #     [nb_nan, residu, aic, redchi, start_anti, maxi, latence, v_anti     ] --> .68 58% 78%\n",
    "              #     [nb_nan, residu, aic, redchi, start_anti, maxi, latence,         tau] --> .68 59% 74%\n",
    "              #     [nb_nan, residu, aic, redchi, start_anti, maxi,          v_anti, tau] --> .66 56% 72%\n",
    "              #     [nb_nan, residu, aic, redchi, start_anti,       latence, v_anti, tau] --> .67 60% 75%\n",
    "              #     \n",
    "              #     [nb_nan, residu, aic, redchi,             maxi, latence, v_anti, tau]\n",
    "              #     [nb_nan, residu, aic,         start_anti, maxi, latence, v_anti, tau]\n",
    "              #     [nb_nan, residu,      redchi, start_anti, maxi, latence, v_anti, tau]\n",
    "              #     [nb_nan,         aic, redchi, start_anti, maxi, latence, v_anti, tau]\n",
    "              #     [        residu, aic, redchi, start_anti, maxi, latence, v_anti, tau]\n",
    "              #-----------------------------------------------------------------------------------------------\n",
    "              #[nb_nan, residu, aic,         bic, start_anti, maxi, latence, v_anti, tau] --> .71    73%   73%\n",
    "              #[nb_nan, residu,      redchi, bic, start_anti, maxi, latence, v_anti, tau] --> .73    78%   68%\n",
    "              #[nb_nan,         aic, redchi, bic, start_anti, maxi, latence, v_anti, tau] --> .71    73%   74%\n",
    "              #[        residu, aic, redchi, bic, start_anti, maxi, latence, v_anti, tau] --> .71    73%   74%\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "        [nb_nan, residu, aic,         nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .67    67%   73%\n",
    "        [nb_nan, residu,      redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .72    56%   81%\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "             [nb_nan, residu, redchi, nfev, bic, start_anti, maxi, latence, v_anti     ] --> .56   100%    0%\n",
    "             [nb_nan, residu, redchi, nfev, bic, start_anti, maxi, latence,         tau] --> .56   100%    0%\n",
    "             [nb_nan, residu, redchi, nfev, bic, start_anti, maxi,          v_anti, tau] --> .56   100%    0%\n",
    "             [nb_nan, residu, redchi, nfev, bic, start_anti,       latence, v_anti, tau] --> .55    89%   14%\n",
    "             [nb_nan, residu, redchi, nfev, bic,             maxi, latence, v_anti, tau] --> .56   100%    0%\n",
    "             [nb_nan, residu, redchi, nfev,      start_anti, maxi, latence, v_anti, tau] --> .63    51%   77%\n",
    "\n",
    "             [nb_nan, residu, redchi, nfev,      start_anti, maxi, latence, v_anti, tau]\n",
    "             [nb_nan, residu, redchi,       bic, start_anti, maxi, latence, v_anti, tau]\n",
    "             [nb_nan, residu,         nfev, bic, start_anti, maxi, latence, v_anti, tau]\n",
    "             [nb_nan,         redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau]\n",
    "             [        residu, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau]\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "        -----------------------------------------------------------------------------------------------------\n",
    "        [nb_nan,         aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .67    66%   73%\n",
    "        [        residu, aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .67    66%   73%\n",
    "-------------------------------------------------------------------------------------------------------------\n",
    "[nb_nan, residu,      chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .52    100%   0%\n",
    "[nb_nan,         aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .53    100%   0%\n",
    "[        residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .53    100%   0%"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "|-----------------------------------|\n",
    "|     Moyenne quand fit 2 par 2     |\n",
    "|-----------------------------------|\n",
    "|tau ---------->  .689     73%  63% |\n",
    "|nb_nan ------->  .685     74%  64% |\n",
    "|residu ------->  .670     71%  61% |\n",
    "|bic ---------->  .661     69%  61% |\n",
    "|latence ------>  .660     71%  60% |\n",
    "|maxi --------->  .655     72%  56% |\n",
    "|v_anti  ------>  .648     69%  58% |\n",
    "|start_anti --->  .626     73%  49% |\n",
    "|aic ---------->  .596     69%  48% |\n",
    "|redchi ------->  .596     61%  59% |\n",
    "|nfev --------->  .591     72%  45% |\n",
    "|chisqr ------->  .590     61%  52% |\n",
    "|-----------------------------------|"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    " Dans l'ordre !!!\n",
    "---------------------------------------\n",
    "---------------------------------------\n",
    "> .77 - [nb_nan, tau, residu] --> .78 85% 64%\n",
    "---------------------------------------\n",
    "nb_nan - tau :         .81     86%  75%\n",
    "nb_nan - residu :      .78     82%  71%\n",
    "residu - tau :         .77     79%  68%\n",
    "---------------------------------------\n",
    "> .75 - [nb_nan, tau, residu, v_anti, bic] --> .64 70% 58%\n",
    "---------------------------------------\n",
    "nb_nan - v_anti :      .76     84%  66%\n",
    "tau - v_anti :         .75     84%  59%\n",
    "bic - tau :            .75     75%  68%\n",
    "---------------------------------------\n",
    "> .70 - [nb_nan, tau, residu, v_anti, bic, maxi, latence] --> .66 69% 66%\n",
    "---------------------------------------\n",
    "nb_nan - bic :         .73     78%  65%\n",
    "tau - maxi :           .72     74%  67%\n",
    "bic - maxi :           .71     80%  54%\n",
    "nb_nan - latence :     .71     75%  75%\n",
    "nb_nan - maxi :        .70     86%  58%\n",
    "bic - latence :        .70     81%  56%\n",
    "residu - maxi :        .70     77%  61%\n",
    "---------------------------------------\n",
    "> .65 - [nb_nan, tau, residu, v_anti, bic, maxi, latence, start_anti] --> .68 61% 71%\n",
    "---------------------------------------\n",
    "residu - latence :     .69     77%  62%\n",
    "latence - maxi :       .69     75%  60%\n",
    "tau - latence :        .69     71%  70%\n",
    "start_anti - tau :     .68     83%  52%\n",
    "residu - bic :         .68     69%  62%\n",
    "v_anti - latence :     .68     67%  66%\n",
    "residu - v_anti :      .67     79%  53%\n",
    "bic - v_anti :         .67     76%  59%\n",
    "residu - start_anti :  .66     75%  51%\n",
    "bic - start_anti :     .66     68%  61%\n",
    "nb_nan - start_anti :  .65     85%  53%\n",
    "---------------------------------------\n",
    "> .60 - [nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> .54 100% 0%\n",
    "---------------------------------------\n",
    "nfev - latence :       .64     73%  52%\n",
    "start_anti - latence : .64     74%  50%\n",
    "start_anti - maxi :    .64     74%  45%\n",
    "v_anti - maxi :        .64     71%  51%\n",
    "bic - nfev :           .64     65%  67%\n",
    "aic - start_anti :     .63     63%  59%\n",
    "redchi - start_anti :  .63     63%  61%\n",
    "nfev - maxi :          .62     69%  51%\n",
    "redchi - tau :         .62     54%  79%\n",
    "chisqr - latence :     .62     51%  70%\n",
    "residu - nfev :        .61     72%  51%\n",
    "aic - latence :        .61     70%  51%\n",
    "redchi - maxi :        .61     67%  57%\n",
    "chisqr - tau :         .61     52%  68%\n",
    "residu - chisqr :      .61     53%  67%\n",
    "nb_nan - chisqr :      .61     53%  67%\n",
    "redchi - v_anti :      .61     51%  66%\n",
    "chisqr - start_anti :  .61     51%  69%\n",
    "residu - redchi :      .61     50%  71%\n",
    "nb_nan - nfev :        .60     78%  49%\n",
    "nb_nan - aic :         .60     72%  48%\n",
    "redchi - latence :     .60     70%  52%\n",
    "residu - aic :         .60     68%  52%\n",
    "aic - v_anti :         .60     65%  53%\n",
    "aic - tau :            .60     63%  56%\n",
    "chisqr - v_anti :      .60     50%  71%\n",
    "---------------------------------------\n",
    "< .60 - nb_nan - tau - - v_anti - bic - maxi - - start_anti - nfev -  aic - redchi - chisqr \n",
    "---------------------------------------\n",
    "aic - bic :            .59     70%  49%\n",
    "redchi - bic :         .59     71%  53%\n",
    "aic - maxi :           .59     67%  53%\n",
    "aic - nfev :           .59     59%  55%\n",
    "chisqr - maxi :        .59     56%  67%\n",
    "redchi - nfev :        .59     44%  74%\n",
    "nb_nan - redchi :      .59     39%  79%\n",
    "aic - chisqr :         .58     99%   1%\n",
    "nfev - tau :           .58     82%  41%\n",
    "start_anti - v_anti :  .58     70%  46%\n",
    "aic - redchi :         .57     65%  55%\n",
    "nfev - v_anti :        .57     63%  50%\n",
    "nfev - chisqr :        .56     93%   9%\n",
    "bic - chisqr :         .56     26%  82%\n",
    "redchi - chisqr :      .54     97%   2%\n",
    "nfev - start_anti :    .51    100%   1%\n",
    "---------------------------------------"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "liste = ['nb_nan', 'residu', 'aic', 'redchi',      'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "\n",
    "l = []\n",
    "_ = [[[[[[[[[\n",
    "    l.append([liste[a], liste[b], liste[c], liste[d],\n",
    "              liste[e], liste[f], liste[g], liste[h]])\n",
    "    for h in range(g+1, len(liste))]\n",
    "    for g in range(f+1, len(liste))] for f in range(e+1, len(liste))]\n",
    "    for e in range(d+1, len(liste))] for d in range(c+1, len(liste))]\n",
    "    for c in range(b+1, len(liste))] for b in range(a+1, len(liste))]\n",
    "    for a in range(len(liste))]]\n",
    "\n",
    "'''\n",
    "_ = [[[[[[[[[[[[\n",
    "    l.append([liste[a], liste[b], liste[c], liste[d],\n",
    "              liste[e], liste[f], liste[g], liste[h],\n",
    "              liste[i], liste[j], liste[k]])\n",
    "    for k in range(j+1, len(liste))] for j in range(i+1, len(liste))]\n",
    "    for i in range(h+1, len(liste))] for h in range(g+1, len(liste))]\n",
    "    for g in range(f+1, len(liste))] for f in range(e+1, len(liste))]\n",
    "    for e in range(d+1, len(liste))] for d in range(c+1, len(liste))]\n",
    "    for c in range(b+1, len(liste))] for b in range(a+1, len(liste))]\n",
    "    for a in range(len(liste))]]\n",
    "'''\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

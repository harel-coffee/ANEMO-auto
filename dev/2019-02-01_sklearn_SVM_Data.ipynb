{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " - utiliser juste deux classes : keep / reject\n",
    " - multi-variate X en fonction du dictionaire incluant list_keys_param_fit et goodness_of_fit\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "#from sklearn import svm, datasets\n",
    "%matplotlib inline\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')  # \"error\", \"ignore\", \"always\", \"default\", \"module\" or \"once\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 1- Split into a training set and a test set using a ShuffleSplit + doing that in parallel for the differrent features to test\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import ShuffleSplit\n",
    "def split_data(X, y, test_size=.25, train_size=None) :\n",
    "    \n",
    "\n",
    "    rs = ShuffleSplit(n_splits=1, test_size=test_size, train_size=train_size, random_state=0)\n",
    "    for index_train, index_test in rs.split(y): pass\n",
    "\n",
    "    X_train, X_test = {}, {}\n",
    "    X_train, X_test = X[index_train, :], X[index_test, :]\n",
    "    y_train, y_test =  y[index_train].copy(), y[index_test].copy()\n",
    "\n",
    "    print('nb_trial_train : X: %s, y: %s'%(X_train.shape[0], y_train.shape[0]), end='\\t')\n",
    "    print('nb_trial_test : X: %s,  y: %s'%(X_test.shape[0], y_test.shape[0]))\n",
    "    return X_train, X_test, y_train, y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 4- Train a SVM classification model\n",
    "#------------------------------------------------------------------------------\n",
    "\n",
    "from sklearn.model_selection import GridSearchCV # see http://scikit-learn.org/stable/modules/grid_search.html\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "def Train_SVM(X_train, y_train, size_c_gamma=32, ax=None, fig=None, plot=None) :\n",
    "\n",
    "\n",
    "    C_range = np.logspace(-5, 10., size_c_gamma, base=2.)\n",
    "    gamma_range = np.logspace(-14, 3, size_c_gamma, base=2.)\n",
    "\n",
    "    \n",
    "\n",
    "    '''param_grid = [{'kernel': ['rbf', 'poly', 'sigmoid'], 'gamma': gamma_range, 'C': C_range},\n",
    "                  {'kernel': ['linear'], 'C': C_range}]'''\n",
    "    \n",
    "    liste_kernel = ['rbf']#, 'poly', 'sigmoid']\n",
    "    param_grid = [{'kernel': liste_kernel, 'gamma': gamma_range, 'C': C_range}]\n",
    "\n",
    "    \n",
    "    grid = GridSearchCV(SVC(verbose=False, tol=1e-3, max_iter = -1, class_weight='balanced'),\n",
    "                        param_grid, verbose=0, scoring='balanced_accuracy', n_jobs=1,) #cv=50, \n",
    "    # TODO: test scoring='balanced_accuracy'\n",
    "\n",
    "    X_train_ = np.zeros((len(X_train), 0))\n",
    "    X_train_ = np.hstack((X_train_, X_train))\n",
    "    grid.fit(X_train, y_train.ravel())\n",
    "\n",
    "\n",
    "    # plot the scores of the grid\n",
    "\n",
    "    means = grid.cv_results_['mean_test_score']\n",
    "    stds = grid.cv_results_['std_test_score']\n",
    "    \n",
    "    scores_mean, scores_std = {}, {}\n",
    "    #for params, mean_score, scores in score_dict:\n",
    "    for mean_score, std, params in zip(means, stds, grid.cv_results_['params']):\n",
    "        try :\n",
    "            scores_mean[params['kernel']].append(mean_score)\n",
    "            scores_std[params['kernel']].append(std)\n",
    "        except:\n",
    "            scores_mean[params['kernel']] = []\n",
    "            scores_std[params['kernel']] = []\n",
    "            scores_mean[params['kernel']].append(mean_score)\n",
    "            scores_std[params['kernel']].append(std)\n",
    "\n",
    "\n",
    "    # draw heatmap of accuracy as a function of gamma and C    \n",
    "    if plot is None :\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "\n",
    "    for x, k in enumerate(['rbf']): #, 'poly', 'sigmoid']) :\n",
    "        scores = np.array(scores_mean[k]).reshape((gamma_range.shape[0], C_range.shape[0]))\n",
    "        im = ax.imshow(scores, interpolation='nearest', cmap=plt.cm.gray)\n",
    "        ax.set_xlabel('gamma')\n",
    "        ax.set_ylabel('C')\n",
    "        #ax.set_colorbar()\n",
    "        ax.set_title(k)\n",
    "        fig.colorbar(im, ax=ax, pad=0.01, fraction=.047)\n",
    "    \n",
    "    if plot is None :\n",
    "        fig.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    print(\"The best parameters are %s with a score of %0.2f\" % (grid.best_params_, grid.best_score_))\n",
    "    \n",
    "    if plot is None :\n",
    "        return grid\n",
    "    else :\n",
    "        return ax, fig, grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#------------------------------------------------------------------------------\n",
    "# 5- Quantitative evaluation of the model quality on the test set\n",
    "#------------------------------------------------------------------------------\n",
    "def Quantitative_evaluation(grid, X_test, y_test, classes, ax=None, fig=None, plot=None) :\n",
    "\n",
    "    import itertools\n",
    "    from sklearn import metrics\n",
    "    from sklearn.metrics import classification_report\n",
    "    from sklearn.metrics import confusion_matrix\n",
    "\n",
    "    \n",
    "    y_pred = grid.predict(X_test)\n",
    "    # see https://en.wikipedia.org/wiki/F1_score\n",
    "    fone_score = np.array(metrics.f1_score(y_test, y_pred, average=None)).mean()\n",
    "    \n",
    "    #print(\"Predicting the category names on the testing set\")\n",
    "    #print('\\nclassification_report on test \\n', classification_report(y_test, y_pred, target_names=classes))\n",
    "    \n",
    "    \n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    norm_cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "    \n",
    "    if plot is None :\n",
    "        fig, ax = plt.subplots(1,1,figsize=(5,5))\n",
    "    im = ax.imshow(norm_cm, interpolation='nearest', cmap=plt.cm.Reds)\n",
    "    \n",
    "    ax.set_title('Confusion matrix\\n(fone_score on test => Accuracy = %0.2f)' % (fone_score))\n",
    "    fig.colorbar(im, ax=ax, pad=0.01, fraction=.047)\n",
    "    \n",
    "    tick_marks = np.arange(len(classes))\n",
    "    ax.set_xticks(tick_marks)\n",
    "    ax.set_yticks(tick_marks)\n",
    "    ax.set_xticklabels(classes)\n",
    "    ax.set_yticklabels(classes)\n",
    "    \n",
    "    thresh = norm_cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        ax.text(j, i, 'nb_trial = %s\\n\\n(%.0f %%)'%(cm[i, j], norm_cm[i, j]*100),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if norm_cm[i, j] > thresh else \"black\")\n",
    "        if i==j :\n",
    "            ax.text(j, i+0.2, 'f1_score = %.2f'%(metrics.f1_score(y_test, y_pred, average=None)[i]),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if norm_cm[i, j] > thresh else \"black\")\n",
    "        \n",
    "\n",
    "    ax.set_ylabel('True label')\n",
    "    ax.set_xlabel('Predicted label')\n",
    "    \n",
    "    if plot is None :\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "\n",
    "        return y_pred\n",
    "    else :\n",
    "        return ax, fig, y_pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "import os\n",
    "from ANEMO import read_edf\n",
    "from ANEMO import ANEMO\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "sujet = ['AM','BMC','CS','DC','FM','IP','LB','OP','RS','SR','TN','YK']\n",
    "time = ['2017-10-23_100057','2017-09-26_095637', '2017-10-03_134421','2017-09-27_161040',\n",
    "        '2017-10-03_143803','2017-09-28_115250', '2017-09-20_151043','2017-10-26_121823',\n",
    "        '2017-11-08_094717','2017-11-16_153313', '2017-11-08_150410','2017-11-17_172706']\n",
    "file = os.path.join('parametre', 'Delete_list_trials_velocity_fct.pkl')\n",
    "with open(file, 'rb') as fichier :\n",
    "    Delete_list_trials = pickle.load(fichier, encoding='latin1')\n",
    "\n",
    "file = os.path.join('parametre', 'Delete_list_Bad_trials_velocity.pkl')\n",
    "with open(file, 'rb') as fichier :\n",
    "    Bad_Fit = pickle.load(fichier, encoding='latin1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AM -- nb_Delete_trials = [0, 1, 0], nb_Bad_Fit = [1, 0, 0]\n",
      "BMC -- nb_Delete_trials = [2, 7, 2], nb_Bad_Fit = [0, 1, 3]\n",
      "CS -- nb_Delete_trials = [0, 0, 2], nb_Bad_Fit = [3, 16, 10]\n",
      "DC -- nb_Delete_trials = [3, 7, 2], nb_Bad_Fit = [6, 7, 6]\n",
      "FM -- nb_Delete_trials = [22, 11, 3], nb_Bad_Fit = [3, 3, 3]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-22e80633d45c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     51\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvelocity_NAN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m280\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     52\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misnan\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvelocity_NAN\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnan\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 53\u001b[0;31m                 \u001b[0;32melse\u001b[0m \u001b[0;34m:\u001b[0m \u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgoodness_of_fit\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'residual'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mblock\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtrial\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m;\u001b[0m \u001b[0mt1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mt1\u001b[0m\u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     54\u001b[0m             \u001b[0mresidu\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnanmean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mres\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mStimulusOf\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0marg\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mt_0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "list_keys_param_fit = ['start_anti', 'tau', 'v_anti', 'latence', 'maxi']\n",
    "X, y, var = [], [], []\n",
    "a = 0\n",
    "for x in range(len(sujet)) :\n",
    "    \n",
    "    #-------------------------------------------------------------------------\n",
    "    file = os.path.join('data', 'enregistrement_' + sujet[x] + '_' + time[x] + '.pkl')\n",
    "    with open(file, 'rb') as fichier : param_exp = pickle.load(fichier, encoding='latin1')\n",
    "    A = ANEMO(param_exp)\n",
    "    N_trials, N_blocks = param_exp['N_trials'], param_exp['N_blocks']\n",
    "\n",
    "    resultats = os.path.join('data', 'enregistrement_' + sujet[x] + '_' + time[x] + '.asc')\n",
    "    data = read_edf(resultats, 'TRIALID')\n",
    "\n",
    "    file = os.path.join('parametre/goodness_of_fit_'+ sujet[x] +'.pkl')\n",
    "    with open(file, 'rb') as fichier : goodness_of_fit = pickle.load(fichier, encoding='latin1')\n",
    "    \n",
    "    file = os.path.join('parametre/param_Fit_'+ sujet[x] +'_fct_velocity_2_step_False_whitening.pkl')\n",
    "    with open(file, 'rb') as fichier : param_fit = pickle.load(fichier, encoding='latin1')\n",
    "    #-------------------------------------------------------------------------\n",
    "\n",
    "    nb_del_trial = [len(Delete_list_trials[sujet[x]][b]) for b in range(N_blocks)]\n",
    "    nb_bad_trial = [len(Bad_Fit[sujet[x]][b]) for b in range(N_blocks)]\n",
    "    print('%s -- nb_Delete_trials = %s, nb_Bad_Fit = %s'%(sujet[x], nb_del_trial, nb_bad_trial))\n",
    "    #-------------------------------------------------------------------------\n",
    "    \n",
    "    for block in range(N_blocks) :\n",
    "        for trial in range(N_trials) :\n",
    "\n",
    "            if trial in Delete_list_trials[sujet[x]][block] : y.append(1)\n",
    "            elif trial in Bad_Fit[sujet[x]][block] : y.append(1)\n",
    "            else : y.append(0)\n",
    "\n",
    "            if a==0 :\n",
    "                var.append('nb_nan') ; X.append([])\n",
    "                var.append('residu') ; X.append([])\n",
    "                for key in goodness_of_fit.keys() :\n",
    "                    if key!='residual' : var.append(key) ; X.append([])\n",
    "                for key in param_fit.keys() :\n",
    "                    if key in list_keys_param_fit : var.append(key) ; X.append([])\n",
    "                a=1\n",
    "            \n",
    "            trial_data = trial + N_trials*block\n",
    "            arg = A.arg(data[trial_data], trial=trial, block=block)\n",
    "            velocity_NAN = A.velocity_NAN(**arg)[0]\n",
    "\n",
    "            nb_nan = [x for x in velocity_NAN[arg.StimulusOf-arg.t_0:] if str(x)=='nan']\n",
    "            X[0].append(len(nb_nan)/len(velocity_NAN[arg.StimulusOf-arg.t_0:]))\n",
    "            \n",
    "            t1 , res = 0, np.zeros(len(velocity_NAN)-280)\n",
    "            for t in range(len(velocity_NAN)-280) :\n",
    "                if np.isnan(velocity_NAN[t]) : res[t] = np.nan\n",
    "                else : res[t] = abs(goodness_of_fit['residual'][block][trial][t1]) ; t1 = t1+1\n",
    "            residu = np.nanmean(res[arg.StimulusOf-arg.t_0:])\n",
    "            \n",
    "            X[1].append(residu)\n",
    "            \n",
    "            k = 2\n",
    "            for key in goodness_of_fit.keys() :\n",
    "                if key!='residual' : X[k].append(goodness_of_fit[key][block][trial]) ; k=k+1\n",
    "    \n",
    "            for key in param_fit.keys() :\n",
    "                if key in list_keys_param_fit : X[k].append(param_fit[key][block][trial]) ; k=k+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(var)\n",
    "print(np.shape(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def figure(l_) :\n",
    "    \n",
    "    X0 = []\n",
    "    for a in l_ :\n",
    "        for b in range(len(var)) :\n",
    "            if a==var[b] :\n",
    "                X0.append(X[b])\n",
    "\n",
    "    X1 = np.array(X0) ; y1 = np.array(y)\n",
    "    X1 = X1.transpose()\n",
    "\n",
    "    X_train, X_test, y_train, y_test = split_data(X1, y1, test_size=.7, train_size=None)\n",
    "    print('nb_Bad_trial -- y_train : %s -- y_test : %s'%(len(y_train[y_train>0]), len(y_test[y_test>0])))\n",
    "\n",
    "    fig, ax = plt.subplots(1,2,figsize=(10*2,10))\n",
    "    X_fit = X_train ; X_t = X_test\n",
    "\n",
    "    classes = ['keep', 'reject']\n",
    "    ax[0], fig, grid = Train_SVM(X_fit, y_train, size_c_gamma=32, ax=ax[0], fig=fig, plot=True)\n",
    "    ax[1], fig, y_pred = Quantitative_evaluation(grid, X_t, y_test, classes, ax=ax[1], fig=fig, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_ = ['nb_nan', 'residu', 'aic', 'chisqr', 'redchi', 'nfev', 'bic', 'start_anti', 'maxi', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_ = ['nb_nan', 'residu', 'start_anti',       'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_ = ['nb_nan', 'residu', 'start_anti',          'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "l_ = [        'residu', 'start_anti', 'latence', 'v_anti', 'tau']\n",
    "figure(l_)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# reporting..."
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "--------------------------------------------------------------------------------------------------\n",
    "\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti     ] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence,         tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi,          v_anti, tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic, start_anti,       latence, v_anti, tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev, bic,             maxi, latence, v_anti, tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi, nfev,      start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr, redchi,       bic, start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "[nb_nan, residu, aic, chisqr,         nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "\n",
    "[nb_nan, residu, aic,         redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.487\n",
    "    ----------------------------------------------------------------------------------------------\n",
    "    [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti     ] --> 0.512\n",
    "    [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi, latence,         tau] --> 0.496\n",
    "    [nb_nan, residu, aic, redchi, nfev, bic, start_anti, maxi,          v_anti, tau] --> 0.530\n",
    "    [nb_nan, residu, aic, redchi, nfev, bic, start_anti,       latence, v_anti, tau] --> 0.486\n",
    "    [nb_nan, residu, aic, redchi, nfev, bic,             maxi, latence, v_anti, tau] --> 0.515\n",
    "    [nb_nan, residu, aic, redchi, nfev,      start_anti, maxi, latence, v_anti, tau] --> 0.509\n",
    "    \n",
    "    [nb_nan, residu, aic, redchi,       bic, start_anti, maxi, latence, v_anti, tau] --> 0.552\n",
    "    ------------------------------------------------------------------------------------------\n",
    "        [nb_nan, residu, aic, redchi, bic, start_anti, maxi, latence, v_anti     ] --> 0.529\n",
    "        [nb_nan, residu, aic, redchi, bic, start_anti, maxi, latence,         tau] --> 0.544\n",
    "        [nb_nan, residu, aic, redchi, bic, start_anti, maxi,          v_anti, tau] --> 0.547\n",
    "        [nb_nan, residu, aic, redchi, bic, start_anti,       latence, v_anti, tau] --> 0.55\n",
    "        [nb_nan, residu, aic, redchi, bic,             maxi, latence, v_anti, tau] --> 0.535\n",
    "        [nb_nan, residu, aic, redchi,      start_anti, maxi, latence, v_anti, tau] --> 0.568\n",
    "        [nb_nan, residu, aic,         bic, start_anti, maxi, latence, v_anti, tau] --> 0.530\n",
    "        \n",
    "        [nb_nan, residu,      redchi, bic, start_anti, maxi, latence, v_anti, tau] --> 0.591\n",
    "        ------------------------------------------------------------------------------------\n",
    "            [nb_nan, residu, redchi, bic, start_anti, maxi, latence, v_anti     ] --> 0.579\n",
    "            [nb_nan, residu, redchi, bic, start_anti, maxi, latence,         tau] --> 0.604\n",
    "            [nb_nan, residu, redchi, bic, start_anti, maxi,          v_anti, tau] --> 0.585\n",
    "            [nb_nan, residu, redchi, bic, start_anti,       latence, v_anti, tau] --> 0.601\n",
    "            [nb_nan, residu, redchi, bic,             maxi, latence, v_anti, tau] --> 0.591\n",
    "            \n",
    "            [nb_nan, residu, redchi,      start_anti, maxi, latence, v_anti, tau] --> 0.641\n",
    "            -------------------------------------------------------------------------------\n",
    "            \n",
    "                [nb_nan, residu, redchi, start_anti, maxi, latence, v_anti     ] --> 0.635\n",
    "                [nb_nan, residu, redchi, start_anti, maxi, latence,         tau] --> 0.637\n",
    "                [nb_nan, residu, redchi, start_anti, maxi,          v_anti, tau] --> 0.604\n",
    "                [nb_nan, residu, redchi, start_anti,       latence, v_anti, tau] --> 0.636\n",
    "                [nb_nan, residu, redchi,             maxi, latence, v_anti, tau] --> 0.628\n",
    "                \n",
    "                [nb_nan, residu,         start_anti, maxi, latence, v_anti, tau] --> 0.641\n",
    "                --------------------------------------------------------------------------\n",
    "                    [nb_nan, residu, start_anti, maxi, latence, v_anti     ] --> 0.656\n",
    "                    [nb_nan, residu, start_anti, maxi, latence,         tau] --> 0.614\n",
    "                    [nb_nan, residu, start_anti, maxi,          v_anti, tau] --> 0.626\n",
    "\n",
    "                    [nb_nan, residu, start_anti,       latence, v_anti, tau] --> 0.679\n",
    "                    ------------------------------------------------------------------\n",
    "                        [nb_nan, residu, start_anti, latence, v_anti     ] --> 0.666\n",
    "                        [nb_nan, residu, start_anti, latence,         tau] --> 0.669\n",
    "                        [nb_nan, residu, start_anti,          v_anti, tau] --> 0.679\n",
    "                        ------------------------------------------------------------\n",
    "                            [nb_nan, residu, start_anti, v_anti     ] --> 0.618\n",
    "                            [nb_nan, residu, start_anti,         tau] --> 0.663\n",
    "                            [nb_nan, residu,             v_anti, tau] --> 0.632\n",
    "                            [nb_nan,         start_anti, v_anti, tau] --> 0.600\n",
    "                            [        residu, start_anti, v_anti, tau] --> 0.662\n",
    "                        ------------------------------------------------------------\n",
    "                        [nb_nan, residu,             latence, v_anti, tau] --> 0.659\n",
    "                        [nb_nan,         start_anti, latence, v_anti, tau] --> 0.607\n",
    "                        \n",
    "                        [        residu, start_anti, latence, v_anti, tau] --> 0.679\n",
    "                        ------------------------------------------------------------\n",
    "                            [residu, start_anti, latence, v_anti     ] --> 0.665\n",
    "                            ----------------------------------------------------\n",
    "                                [residu, start_anti, latence        ] --> 0.627\n",
    "                                [residu, start_anti,          v_anti] --> 0.620\n",
    "                                [residu,             latence, v_anti] --> 0.618\n",
    "                                [        start_anti, latence, v_anti] --> 0.623\n",
    "                            ---------------------------------------------------\n",
    "                            [residu, start_anti, latence,         tau] --> 0.664\n",
    "                            [residu, start_anti,          v_anti, tau] --> 0.662\n",
    "                            [residu,             latence, v_anti, tau] --> 0.664\n",
    "                            [        start_anti, latence, v_anti, tau] --> 0.607\n",
    "                    ------------------------------------------------------------\n",
    "                    [nb_nan, residu,             maxi, latence, v_anti, tau] --> 0.658\n",
    "                    [nb_nan,         start_anti, maxi, latence, v_anti, tau] --> 0.639\n",
    "                    [        residu, start_anti, maxi, latence, v_anti, tau] --> 0.641    \n",
    "                ----------------------------------------------------------------------\n",
    "                [nb_nan,         redchi, start_anti, maxi, latence, v_anti, tau] --> 0.641\n",
    "                [        residu, redchi, start_anti, maxi, latence, v_anti, tau] --> 0.641\n",
    "            ------------------------------------------------------------------------------\n",
    "            [nb_nan, residu,         bic, start_anti, maxi, latence, v_anti, tau] --> 0.583\n",
    "            [nb_nan,         redchi, bic, start_anti, maxi, latence, v_anti, tau] --> 0.591\n",
    "            [        residu, redchi, bic, start_anti, maxi, latence, v_anti, tau] --> 0.590\n",
    "        -----------------------------------------------------------------------------------\n",
    "        [nb_nan,         aic, redchi, bic, start_anti, maxi, latence, v_anti, tau] --> 0.534\n",
    "        [        residu, aic, redchi, bic, start_anti, maxi, latence, v_anti, tau] --> 0.534\n",
    "    ------------------------------------------------------------------------------------------\n",
    "    [nb_nan, residu, aic,         nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.530\n",
    "    [nb_nan, residu,      redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.531\n",
    "    [nb_nan,         aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.526\n",
    "    [        residu, aic, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.526\n",
    "--------------------------------------------------------------------------------------------------\n",
    "[nb_nan, residu,      chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "[nb_nan,         aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.477\n",
    "[        residu, aic, chisqr, redchi, nfev, bic, start_anti, maxi, latence, v_anti, tau] --> 0.477"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "|-------------------------------------|\n",
    "|      Moyenne quand fit 2 par 2      |\n",
    "|-------------------------------------|\n",
    "| nb_nan ------> 0.592 7272727272727  |\n",
    "| maxi --------> 0.586 3636363636363  |\n",
    "| latence -----> 0.561 8181818181819  |\n",
    "| redchi ------> 0.545 4545454545454  |\n",
    "| residu ------> 0.538 1818181818182  |\n",
    "| start_anti --> 0.529 0909090909092  |\n",
    "| v_anti ------> 0.519 090909090909   |\n",
    "| tau ---------> 0.510 9090909090909  |\n",
    "| aic ---------> 0.507 2727272727273  |\n",
    "| nfev --------> 0.502 7272727272728  |\n",
    "| chisqr ------> 0.496 3636363636363  |\n",
    "| bic ---------> 0.495 45454545454554 |\n",
    "|-------------------------------------|"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-------------------------\n",
    "> 60 --- nb_nan-6(.65) - maxi-4(.63) - redchi-3(.63) - latence-3(.62) - residu-2(.66) - v_anti-1(.63) - start_anti-1(.62)\n",
    "-------------------------\n",
    "nb_nan - residu = 0.69\n",
    "nb_nan - redchi = 0.67\n",
    "nb_nan - maxi = 0.67\n",
    "nb_nan - latence = 0.64\n",
    "nb_nan - v_anti = 0.63\n",
    "maxi - residu = 0.63\n",
    "nb_nan - start_anti = 0.62\n",
    "maxi - latence = 0.62\n",
    "redchi - latence = 0.62\n",
    "maxi - redchi = 0.61\n",
    "\n",
    "-------------------------\n",
    "> 55 --- maxi-5(.58) - latence-4(.56) - start_anti-3(.55) - tau-2(.58) - aic-2(.57) - nb_nan-2(.56) - residu-2(.56) - nfev-2(.56) - v_anti-1(.59) - bic-1(.56)\n",
    "-------------------------\n",
    "maxi - tau = 0.59\n",
    "maxi - v_anti = 0.59\n",
    "maxi - start_anti = 0.58\n",
    "maxi - aic = 0.58\n",
    "latence - residu = 0.57\n",
    "nb_nan - tau = 0.57\n",
    "maxi - nfev = 0.56\n",
    "latence - aic = 0.56\n",
    "latence - bic = 0.56\n",
    "nb_nan - nfev = 0.56\n",
    "latence - start_anti = 0.55\n",
    "residu - start_anti = 0.55\n",
    "\n",
    "\n",
    "-------------------------\n",
    "> 50 --- redchi-7(.51) - chisqr-7(.50) - v_anti-5(.51) - start_anti-4(.51) - residu-4(.51) - latence-4(.51) - tau-3(.51) - nfev-3(.50) - aic-3(.51) - bic-3(.50) - maxi-2(.51) - nb_nan-1(.51)\n",
    "-------------------------\n",
    "redchi - aic = 0.54\n",
    "v_anti - latence = 0.54\n",
    "redchi - start_anti = 0.53\n",
    "redchi - tau = 0.52\n",
    "v_anti - start_anti = 0.52\n",
    "residu - tau  = 0.52\n",
    "redchi - chisqr = 0.51\n",
    "redchi - residu  = 0.51\n",
    "redchi - v_anti = 0.51\n",
    "chisqr - nb_nan = 0.51\n",
    "chisqr - residu = 0.51\n",
    "chisqr - maxi = 0.51\n",
    "start_anti - aic  = 0.51\n",
    "latence - tau = 0.51\n",
    "latence - nfev = 0.51\n",
    "bic - maxi = 0.51\n",
    "redchi - bic  = 0.50\n",
    "chisqr - nfev = 0.50\n",
    "chisqr - v_anti = 0.50\n",
    "chisqr - latence = 0.50\n",
    "v_anti - residu = 0.50\n",
    "start_anti - bic = 0.50\n",
    "nfev - aic = 0.50\n",
    "\n",
    "-------------------------\n",
    "< 50 --- bic-7(.48) - aic-6(.48) - nfev-6(.48) - tau-6(.48) - chisqr-4(.48) - v_anti-4(.48) - residu-3(.48) - start_anti-3(.48) - nb_nan-2(.48) - redchi-1(.48)\n",
    "-------------------------\n",
    "nfev - bic = 0.49\n",
    "nfev - start_anti = 0.49\n",
    "start_anti - tau = 0.49\n",
    "nb_nan - aic = 0.48\n",
    "nb_nan - bic = 0.48\n",
    "residu - aic = 0.48\n",
    "residu - bic = 0.48\n",
    "residu - nfev = 0.48\n",
    "nfev - redchi = 0.48\n",
    "nfev - tau = 0.48\n",
    "nfev - v_anti = 0.48\n",
    "chisqr - aic = 0.48\n",
    "chisqr - bic = 0.48\n",
    "chisqr - start_anti = 0.48\n",
    "chisqr - tau = 0.48\n",
    "aic - bic = 0.48\n",
    "aic - tau = 0.49\n",
    "aic - v_anti = 0.48\n",
    "bic - tau = 0.49\n",
    "bic - v_anti = 0.48\n",
    "tau - v_anti = 0.48"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "liste = ['nb_nan', 'residu', 'start_anti',          'v_anti', 'tau']\n",
    "\n",
    "l = []\n",
    "\n",
    "_ = [[[[[[[[[[[[\n",
    "    l.append([liste[a], liste[b], liste[c], liste[d],\n",
    "              liste[e], liste[f], liste[g], liste[h],\n",
    "              liste[i], liste[j], liste[k]])\n",
    "    for k in range(j+1, len(liste))] for j in range(i+1, len(liste))]\n",
    "    for i in range(h+1, len(liste))] for h in range(g+1, len(liste))]\n",
    "    for g in range(f+1, len(liste))] for f in range(e+1, len(liste))]\n",
    "    for e in range(d+1, len(liste))] for d in range(c+1, len(liste))]\n",
    "    for c in range(b+1, len(liste))] for b in range(a+1, len(liste))]\n",
    "    for a in range(len(liste))]]\n",
    "\n",
    "print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
